File copy and stdout ok
Args passed to python script
Tmax 0.4 (h)
Nmodes 2
Nmes 5000
Nint 8000
Use Loss Modes : False
Use both equations : True
Multigrid : True
Ngrid : 5
Ngrid Turn : 200
STD Noise : 0.00e+00
Neurons per layer and per mode : 25
Sparse Data : True
Data location : cylinder_pitot
Desync Sparse Data : False
Sampling of V_in : 2zones
L-BFGS-B optimizer declared with maxit = 1000, maxfun = 1000, ftol = 2.22e-16
Adam optimize declared with learning rate = 1.00e-05
GPU use before loading data
| ID | GPU | MEM |
------------------
|  0 |  2% | 95% |
Loading Sparse Data on cylinder and pitot probes
Generating 8000 points for equations penalization
Method = 2zones
Generating 8000 points for equations penalization
Method = 2zones
Generating 8000 points for equations penalization
Method = 2zones
Generating 8000 points for equations penalization
Method = 2zones
Generating 8000 points for equations penalization
Method = 2zones
Simulation data reading...
Reading flow...
202.575
202.650
202.725
202.800
202.875
202.950
203.025
203.100
203.175
203.250
203.325
203.400
203.475
203.550
203.625
203.700
203.775
203.850
203.925
204.000
204.075
204.150
204.225
204.300
204.375
204.450
204.525
204.600
204.675
204.750
204.825
204.900
204.975
205.050
205.125
205.200
205.275
205.350
205.425
205.500
205.575
205.650
205.725
205.800
205.875
205.950
206.025
206.100
206.175
206.250
206.325
206.400
206.475
206.550
206.625
206.700
206.775
206.850
206.925
207.000
207.075
207.150
207.225
207.300
207.375
207.450
207.525
207.600
207.675
207.750
207.825
207.900
207.975
208.050
208.125
208.200
208.275
208.350
208.425
208.500
208.575
208.650
208.725
208.800
208.875
208.950
209.025
209.100
209.175
209.250
209.325
209.400
209.475
209.550
209.625
209.700
209.775
209.850
209.925
210.000
210.075
210.150
210.225
210.300
210.375
210.450
210.525
210.600
210.675
210.750
210.825
210.900
210.975
211.050
211.125
211.200
211.275
211.350
211.425
211.500
211.575
211.650
211.725
211.800
211.875
211.950
212.025
212.100
212.175
212.250
212.325
212.400
212.475
212.550
212.625
212.700
212.775
212.850
212.925
213.000
213.075
213.150
213.225
213.300
213.375
213.450
213.525
213.600
213.675
213.750
213.825
213.900
213.975
214.050
214.125
214.200
214.275
214.350
214.425
214.500
214.575
214.650
214.725
214.800
214.875
214.950
215.025
215.100
215.175
215.250
215.325
215.400
215.475
215.550
215.625
215.700
215.775
215.850
215.925
216.000
216.075
216.150
216.225
216.300
216.375
216.450
216.525
216.600
216.675
216.750
216.825
216.900
216.975
217.050
217.125
217.200
217.275
217.350
217.425
217.500
217.575
217.650
217.725
217.800
217.875
217.950
218.025
218.100
218.175
218.250
218.325
218.400
218.475
218.550
218.625
218.700
218.775
218.850
218.925
219.000
219.075
219.150
219.225
219.300
219.375
219.450
219.525
219.600
219.675
219.750
219.825
219.900
219.975
220.050
220.125
220.200
220.275
220.350
220.425
220.500
220.575
220.650
220.725
220.800
220.875
220.950
221.025
221.100
221.175
221.250
221.325
221.400
221.475
221.550
221.625
221.700
221.775
221.850
221.925
222.000
222.075
222.150
222.225
222.300
222.375
222.450
222.525
222.600
222.675
222.750
222.825
222.900
222.975
223.050
223.125
223.200
223.275
223.350
223.425
223.500
223.575
223.650
223.725
223.800
223.875
223.950
224.025
224.100
224.175
224.250
224.325
224.400
224.475
224.550
224.625
224.700
224.775
224.850
224.925
225.000
Done!
CPU_TIME = 24.152300 seconds
Reading and cropping simulation data ... ok
Loading validation data set
Generating 80000 points for equations penalization
Method = uniform
Simulation data reading...
Reading flow...
202.575
202.650
202.725
202.800
202.875
202.950
203.025
203.100
203.175
203.250
203.325
203.400
203.475
203.550
203.625
203.700
203.775
203.850
203.925
204.000
204.075
204.150
204.225
204.300
204.375
204.450
204.525
204.600
204.675
204.750
204.825
204.900
204.975
205.050
205.125
205.200
205.275
205.350
205.425
205.500
205.575
205.650
205.725
205.800
205.875
205.950
206.025
206.100
206.175
206.250
206.325
206.400
206.475
206.550
206.625
206.700
206.775
206.850
206.925
207.000
207.075
207.150
207.225
207.300
207.375
207.450
207.525
207.600
207.675
207.750
207.825
207.900
207.975
208.050
208.125
208.200
208.275
208.350
208.425
208.500
208.575
208.650
208.725
208.800
208.875
208.950
209.025
209.100
209.175
209.250
209.325
209.400
209.475
209.550
209.625
209.700
209.775
209.850
209.925
210.000
210.075
210.150
210.225
210.300
210.375
210.450
210.525
210.600
210.675
210.750
210.825
210.900
210.975
211.050
211.125
211.200
211.275
211.350
211.425
211.500
211.575
211.650
211.725
211.800
211.875
211.950
212.025
212.100
212.175
212.250
212.325
212.400
212.475
212.550
212.625
212.700
212.775
212.850
212.925
213.000
213.075
213.150
213.225
213.300
213.375
213.450
213.525
213.600
213.675
213.750
213.825
213.900
213.975
214.050
214.125
214.200
214.275
214.350
214.425
214.500
214.575
214.650
214.725
214.800
214.875
214.950
215.025
215.100
215.175
215.250
215.325
215.400
215.475
215.550
215.625
215.700
215.775
215.850
215.925
216.000
216.075
216.150
216.225
216.300
216.375
216.450
216.525
216.600
216.675
216.750
216.825
216.900
216.975
217.050
217.125
217.200
217.275
217.350
217.425
217.500
217.575
217.650
217.725
217.800
217.875
217.950
218.025
218.100
218.175
218.250
218.325
218.400
218.475
218.550
218.625
218.700
218.775
218.850
218.925
219.000
219.075
219.150
219.225
219.300
219.375
219.450
219.525
219.600
219.675
219.750
219.825
219.900
219.975
220.050
220.125
220.200
220.275
220.350
220.425
220.500
220.575
220.650
220.725
220.800
220.875
220.950
221.025
221.100
221.175
221.250
221.325
221.400
221.475
221.550
221.625
221.700
221.775
221.850
221.925
222.000
222.075
222.150
222.225
222.300
222.375
222.450
222.525
222.600
222.675
222.750
222.825
222.900
222.975
223.050
223.125
223.200
223.275
223.350
223.425
223.500
223.575
223.650
223.725
223.800
223.875
223.950
224.025
224.100
224.175
224.250
224.325
224.400
224.475
224.550
224.625
224.700
224.775
224.850
224.925
225.000
Done!
CPU_TIME = 24.237447 seconds
Reading and cropping simulation data ... ok
GPU use after loading data
| ID | GPU | MEM |
------------------
|  0 |  0% | 95% |
--------------------------------------------
Start training after 252 s
Start L-BFGS-B training
Loss: 2.664e+00
Loss: 8.977e+00
Loss: 1.119e+00
Loss: 9.524e-01
Loss: 8.362e-01
Loss: 8.000e-01
Loss: 7.616e-01
Loss: 7.394e-01
Loss: 7.175e-01
Loss: 6.887e-01
Loss: 6.776e-01
Loss: 6.530e-01
Loss: 6.424e-01
Loss: 6.140e-01
Loss: 5.571e-01
Loss: 4.913e-01
Loss: 4.327e-01
Loss: 3.828e-01
Loss: 3.584e-01
Loss: 3.489e-01
Loss: 3.255e-01
Loss: 3.123e-01
Loss: 2.967e-01
Loss: 2.902e-01
Loss: 2.845e-01
Loss: 2.773e-01
Loss: 2.710e-01
Loss: 2.663e-01
Loss: 2.613e-01
Loss: 2.556e-01
Loss: 2.479e-01
Loss: 2.434e-01
Loss: 2.404e-01
Loss: 2.380e-01
Loss: 2.341e-01
Loss: 2.306e-01
Loss: 2.279e-01
Loss: 2.263e-01
Loss: 2.247e-01
Loss: 2.226e-01
Loss: 2.206e-01
Loss: 2.192e-01
Loss: 2.188e-01
Loss: 2.183e-01
Loss: 2.178e-01
Loss: 2.171e-01
Loss: 2.167e-01
Loss: 2.163e-01
Loss: 2.158e-01
Loss: 2.152e-01
Loss: 2.145e-01
Loss: 2.141e-01
Loss: 2.136e-01
Loss: 2.131e-01
Loss: 2.125e-01
Loss: 2.118e-01
Loss: 2.113e-01
Loss: 2.108e-01
Loss: 2.100e-01
Loss: 2.099e-01
Loss: 2.093e-01
Loss: 2.091e-01
Loss: 2.088e-01
Loss: 2.085e-01
Loss: 2.079e-01
Loss: 2.073e-01
Loss: 2.068e-01
Loss: 2.067e-01
Loss: 2.063e-01
Loss: 2.061e-01
Loss: 2.057e-01
Loss: 2.054e-01
Loss: 2.051e-01
Loss: 2.049e-01
Loss: 2.045e-01
Loss: 2.042e-01
Loss: 2.039e-01
Loss: 2.037e-01
Loss: 2.034e-01
Loss: 2.030e-01
Loss: 2.023e-01
Loss: 2.028e-01
Loss: 2.019e-01
Loss: 2.015e-01
Loss: 2.010e-01
Loss: 2.007e-01
Loss: 1.998e-01
Loss: 2.010e-01
Loss: 1.994e-01
Loss: 1.989e-01
Loss: 1.985e-01
Loss: 1.982e-01
Loss: 1.977e-01
Loss: 1.967e-01
Loss: 1.966e-01
Loss: 1.961e-01
Loss: 1.959e-01
Loss: 1.955e-01
Loss: 1.949e-01
Loss: 1.945e-01
Loss: 1.937e-01
Loss: 1.933e-01
Loss: 1.929e-01
Loss: 1.925e-01
Loss: 1.921e-01
Loss: 1.917e-01
Loss: 1.914e-01
Loss: 1.910e-01
Loss: 1.904e-01
Loss: 1.898e-01
Loss: 1.893e-01
Loss: 1.890e-01
Loss: 1.887e-01
Loss: 1.883e-01
Loss: 1.878e-01
Loss: 1.874e-01
Loss: 1.868e-01
Loss: 1.862e-01
Loss: 1.855e-01
Loss: 1.852e-01
Loss: 1.844e-01
Loss: 1.843e-01
Loss: 1.836e-01
Loss: 1.833e-01
Loss: 1.829e-01
Loss: 1.824e-01
Loss: 1.820e-01
Loss: 1.815e-01
Loss: 1.811e-01
Loss: 1.807e-01
Loss: 1.803e-01
Loss: 1.797e-01
Loss: 1.791e-01
Loss: 1.787e-01
Loss: 1.782e-01
Loss: 1.776e-01
Loss: 1.772e-01
Loss: 1.768e-01
Loss: 1.762e-01
Loss: 1.758e-01
Loss: 1.753e-01
Loss: 1.750e-01
Loss: 1.746e-01
Loss: 1.741e-01
Loss: 1.737e-01
Loss: 1.733e-01
Loss: 1.728e-01
Loss: 1.725e-01
Loss: 1.722e-01
Loss: 1.719e-01
Loss: 1.715e-01
Loss: 1.710e-01
Loss: 1.706e-01
Loss: 1.702e-01
Loss: 1.700e-01
Loss: 1.696e-01
Loss: 1.693e-01
Loss: 1.689e-01
Loss: 1.686e-01
Loss: 1.684e-01
Loss: 1.680e-01
Loss: 1.676e-01
Loss: 1.672e-01
Loss: 1.668e-01
Loss: 1.665e-01
Loss: 1.660e-01
Loss: 1.656e-01
Loss: 1.653e-01
Loss: 1.649e-01
Loss: 1.646e-01
Loss: 1.642e-01
Loss: 1.639e-01
Loss: 1.636e-01
Loss: 1.633e-01
Loss: 1.630e-01
Loss: 1.625e-01
Loss: 1.620e-01
Loss: 1.616e-01
Loss: 1.613e-01
Loss: 1.610e-01
Loss: 1.607e-01
Loss: 1.604e-01
Loss: 1.602e-01
Loss: 1.600e-01
Loss: 1.597e-01
Loss: 1.595e-01
Loss: 1.592e-01
Loss: 1.590e-01
Loss: 1.589e-01
Loss: 1.584e-01
Loss: 1.583e-01
Loss: 1.579e-01
Loss: 1.577e-01
Loss: 1.575e-01
Loss: 1.572e-01
Loss: 1.569e-01
Loss: 1.565e-01
Loss: 1.564e-01
Loss: 1.561e-01
Loss: 1.559e-01
Loss: 1.556e-01
Loss: 1.553e-01
Loss: 1.549e-01
Loss: 1.547e-01
Loss: 1.544e-01
Loss: 1.542e-01
Loss: 1.540e-01
Loss: 1.538e-01
Loss: 1.536e-01
Loss: 1.535e-01
Loss: 1.533e-01
Loss: 1.530e-01
Loss: 1.529e-01
Loss: 1.527e-01
Loss: 1.525e-01
Loss: 1.523e-01
Loss: 1.521e-01
Loss: 1.519e-01
Loss: 1.518e-01
Loss: 1.514e-01
Loss: 1.513e-01
Loss: 1.511e-01
Loss: 1.510e-01
Loss: 1.508e-01
Loss: 1.507e-01
Loss: 1.504e-01
Loss: 1.502e-01
Loss: 1.500e-01
Loss: 1.498e-01
Loss: 1.496e-01
Loss: 1.494e-01
Loss: 1.493e-01
Loss: 1.492e-01
Loss: 1.489e-01
Loss: 1.488e-01
Loss: 1.486e-01
Loss: 1.484e-01
Loss: 1.482e-01
Loss: 1.480e-01
Loss: 1.478e-01
Loss: 1.477e-01
Loss: 1.476e-01
Loss: 1.474e-01
Loss: 1.473e-01
Loss: 1.473e-01
Loss: 1.470e-01
Loss: 1.469e-01
Loss: 1.468e-01
Loss: 1.466e-01
Loss: 1.466e-01
Loss: 1.464e-01
Loss: 1.463e-01
Loss: 1.461e-01
Loss: 1.459e-01
Loss: 1.457e-01
Loss: 1.456e-01
Loss: 1.454e-01
Loss: 1.453e-01
Loss: 1.452e-01
Loss: 1.450e-01
Loss: 1.449e-01
Loss: 1.448e-01
Loss: 1.447e-01
Loss: 1.445e-01
Loss: 1.444e-01
Loss: 1.442e-01
Loss: 1.441e-01
Loss: 1.439e-01
Loss: 1.438e-01
Loss: 1.436e-01
Loss: 1.434e-01
Loss: 1.433e-01
Loss: 1.432e-01
Loss: 1.430e-01
Loss: 1.429e-01
Loss: 1.428e-01
Loss: 1.427e-01
Loss: 1.426e-01
Loss: 1.424e-01
Loss: 1.423e-01
Loss: 1.422e-01
Loss: 1.421e-01
Loss: 1.420e-01
Loss: 1.418e-01
Loss: 1.416e-01
Loss: 1.415e-01
Loss: 1.414e-01
Loss: 1.413e-01
Loss: 1.412e-01
Loss: 1.410e-01
Loss: 1.409e-01
Loss: 1.408e-01
Loss: 1.406e-01
Loss: 1.405e-01
Loss: 1.404e-01
Loss: 1.404e-01
Loss: 1.403e-01
Loss: 1.401e-01
Loss: 1.400e-01
Loss: 1.399e-01
Loss: 1.398e-01
Loss: 1.397e-01
Loss: 1.396e-01
Loss: 1.395e-01
Loss: 1.394e-01
Loss: 1.393e-01
Loss: 1.391e-01
Loss: 1.390e-01
Loss: 1.389e-01
Loss: 1.388e-01
Loss: 1.387e-01
Loss: 1.386e-01
Loss: 1.385e-01
Loss: 1.384e-01
Loss: 1.383e-01
Loss: 1.382e-01
Loss: 1.381e-01
Loss: 1.380e-01
Loss: 1.379e-01
Loss: 1.378e-01
Loss: 1.377e-01
Loss: 1.377e-01
Loss: 1.376e-01
Loss: 1.375e-01
Loss: 1.374e-01
Loss: 1.373e-01
Loss: 1.373e-01
Loss: 1.372e-01
Loss: 1.371e-01
Loss: 1.370e-01
Loss: 1.369e-01
Loss: 1.368e-01
Loss: 1.367e-01
Loss: 1.366e-01
Loss: 1.365e-01
Loss: 1.364e-01
Loss: 1.363e-01
Loss: 1.363e-01
Loss: 1.362e-01
Loss: 1.361e-01
Loss: 1.361e-01
Loss: 1.360e-01
Loss: 1.359e-01
Loss: 1.358e-01
Loss: 1.357e-01
Loss: 1.357e-01
Loss: 1.356e-01
Loss: 1.355e-01
Loss: 1.354e-01
Loss: 1.353e-01
Loss: 1.353e-01
Loss: 1.352e-01
Loss: 1.351e-01
Loss: 1.351e-01
Loss: 1.350e-01
Loss: 1.349e-01
Loss: 1.350e-01
Loss: 1.348e-01
Loss: 1.347e-01
Loss: 1.347e-01
Loss: 1.346e-01
Loss: 1.345e-01
Loss: 1.344e-01
Loss: 1.343e-01
Loss: 1.343e-01
Loss: 1.342e-01
Loss: 1.342e-01
Loss: 1.341e-01
Loss: 1.341e-01
Loss: 1.340e-01
Loss: 1.339e-01
Loss: 1.339e-01
Loss: 1.338e-01
Loss: 1.338e-01
Loss: 1.337e-01
Loss: 1.337e-01
Loss: 1.336e-01
Loss: 1.335e-01
Loss: 1.335e-01
Loss: 1.334e-01
Loss: 1.334e-01
Loss: 1.333e-01
Loss: 1.333e-01
Loss: 1.332e-01
Loss: 1.332e-01
Loss: 1.332e-01
Loss: 1.331e-01
Loss: 1.331e-01
Loss: 1.331e-01
Loss: 1.330e-01
Loss: 1.330e-01
Loss: 1.329e-01
Loss: 1.329e-01
Loss: 1.329e-01
Loss: 1.328e-01
Loss: 1.328e-01
Loss: 1.327e-01
Loss: 1.327e-01
Loss: 1.327e-01
Loss: 1.326e-01
Loss: 1.326e-01
Loss: 1.325e-01
Loss: 1.325e-01
Loss: 1.324e-01
Loss: 1.324e-01
Loss: 1.323e-01
Loss: 1.323e-01
Loss: 1.323e-01
Loss: 1.323e-01
Loss: 1.322e-01
Loss: 1.322e-01
Loss: 1.322e-01
Loss: 1.321e-01
Loss: 1.321e-01
Loss: 1.320e-01
Loss: 1.320e-01
Loss: 1.319e-01
Loss: 1.319e-01
Loss: 1.318e-01
Loss: 1.318e-01
Loss: 1.317e-01
Loss: 1.317e-01
Loss: 1.317e-01
Loss: 1.316e-01
Loss: 1.316e-01
Loss: 1.316e-01
Loss: 1.315e-01
Loss: 1.315e-01
Loss: 1.315e-01
Loss: 1.315e-01
Loss: 1.314e-01
Loss: 1.314e-01
Loss: 1.313e-01
Loss: 1.313e-01
Loss: 1.312e-01
Loss: 1.312e-01
Loss: 1.312e-01
Loss: 1.311e-01
Loss: 1.311e-01
Loss: 1.310e-01
Loss: 1.310e-01
Loss: 1.310e-01
Loss: 1.309e-01
Loss: 1.309e-01
Loss: 1.309e-01
Loss: 1.309e-01
Loss: 1.308e-01
Loss: 1.308e-01
Loss: 1.308e-01
Loss: 1.308e-01
Loss: 1.307e-01
Loss: 1.307e-01
Loss: 1.307e-01
Loss: 1.306e-01
Loss: 1.306e-01
Loss: 1.305e-01
Loss: 1.305e-01
Loss: 1.305e-01
Loss: 1.304e-01
Loss: 1.304e-01
Loss: 1.304e-01
Loss: 1.303e-01
Loss: 1.303e-01
Loss: 1.303e-01
Loss: 1.302e-01
Loss: 1.302e-01
Loss: 1.302e-01
Loss: 1.302e-01
Loss: 1.301e-01
Loss: 1.301e-01
Loss: 1.301e-01
Loss: 1.300e-01
Loss: 1.300e-01
Loss: 1.300e-01
Loss: 1.299e-01
Loss: 1.299e-01
Loss: 1.298e-01
Loss: 1.298e-01
Loss: 1.298e-01
Loss: 1.297e-01
Loss: 1.297e-01
Loss: 1.297e-01
Loss: 1.297e-01
Loss: 1.296e-01
Loss: 1.296e-01
Loss: 1.295e-01
Loss: 1.295e-01
Loss: 1.295e-01
Loss: 1.294e-01
Loss: 1.294e-01
Loss: 1.294e-01
Loss: 1.293e-01
Loss: 1.293e-01
Loss: 1.293e-01
Loss: 1.292e-01
Loss: 1.292e-01
Loss: 1.292e-01
Loss: 1.291e-01
Loss: 1.291e-01
Loss: 1.291e-01
Loss: 1.290e-01
Loss: 1.290e-01
Loss: 1.289e-01
Loss: 1.289e-01
Loss: 1.289e-01
Loss: 1.288e-01
Loss: 1.288e-01
Loss: 1.288e-01
Loss: 1.287e-01
Loss: 1.287e-01
Loss: 1.287e-01
Loss: 1.286e-01
Loss: 1.286e-01
Loss: 1.286e-01
Loss: 1.285e-01
Loss: 1.285e-01
Loss: 1.285e-01
Loss: 1.284e-01
Loss: 1.284e-01
Loss: 1.284e-01
Loss: 1.283e-01
Loss: 1.283e-01
Loss: 1.283e-01
Loss: 1.283e-01
Loss: 1.282e-01
Loss: 1.282e-01
Loss: 1.281e-01
Loss: 1.281e-01
Loss: 1.280e-01
Loss: 1.280e-01
Loss: 1.279e-01
Loss: 1.279e-01
Loss: 1.278e-01
Loss: 1.277e-01
Loss: 1.277e-01
Loss: 1.276e-01
Loss: 1.276e-01
Loss: 1.276e-01
Loss: 1.275e-01
Loss: 1.275e-01
Loss: 1.274e-01
Loss: 1.274e-01
Loss: 1.274e-01
Loss: 1.273e-01
Loss: 1.273e-01
Loss: 1.272e-01
Loss: 1.272e-01
Loss: 1.272e-01
Loss: 1.271e-01
Loss: 1.271e-01
Loss: 1.270e-01
Loss: 1.270e-01
Loss: 1.269e-01
Loss: 1.269e-01
Loss: 1.268e-01
Loss: 1.267e-01
Loss: 1.267e-01
Loss: 1.266e-01
Loss: 1.265e-01
Loss: 1.265e-01
Loss: 1.264e-01
Loss: 1.264e-01
Loss: 1.264e-01
Loss: 1.263e-01
Loss: 1.262e-01
Loss: 1.262e-01
Loss: 1.261e-01
Loss: 1.261e-01
Loss: 1.260e-01
Loss: 1.260e-01
Loss: 1.259e-01
Loss: 1.259e-01
Loss: 1.258e-01
Loss: 1.258e-01
Loss: 1.257e-01
Loss: 1.257e-01
Loss: 1.257e-01
Loss: 1.256e-01
Loss: 1.256e-01
Loss: 1.255e-01
Loss: 1.255e-01
Loss: 1.254e-01
Loss: 1.254e-01
Loss: 1.254e-01
Loss: 1.253e-01
Loss: 1.253e-01
Loss: 1.252e-01
Loss: 1.251e-01
Loss: 1.251e-01
Loss: 1.250e-01
Loss: 1.250e-01
Loss: 1.250e-01
Loss: 1.249e-01
Loss: 1.248e-01
Loss: 1.248e-01
Loss: 1.247e-01
Loss: 1.247e-01
Loss: 1.246e-01
Loss: 1.246e-01
Loss: 1.246e-01
Loss: 1.245e-01
Loss: 1.244e-01
Loss: 1.244e-01
Loss: 1.244e-01
Loss: 1.243e-01
Loss: 1.242e-01
Loss: 1.241e-01
Loss: 1.241e-01
Loss: 1.240e-01
Loss: 1.240e-01
Loss: 1.239e-01
Loss: 1.239e-01
Loss: 1.238e-01
Loss: 1.238e-01
Loss: 1.237e-01
Loss: 1.237e-01
Loss: 1.236e-01
Loss: 1.236e-01
Loss: 1.235e-01
Loss: 1.235e-01
Loss: 1.234e-01
Loss: 1.233e-01
Loss: 1.233e-01
Loss: 1.232e-01
Loss: 1.231e-01
Loss: 1.231e-01
Loss: 1.230e-01
Loss: 1.230e-01
Loss: 1.229e-01
Loss: 1.229e-01
Loss: 1.228e-01
Loss: 1.227e-01
Loss: 1.227e-01
Loss: 1.226e-01
Loss: 1.226e-01
Loss: 1.226e-01
Loss: 1.225e-01
Loss: 1.225e-01
Loss: 1.224e-01
Loss: 1.224e-01
Loss: 1.223e-01
Loss: 1.222e-01
Loss: 1.222e-01
Loss: 1.221e-01
Loss: 1.220e-01
Loss: 1.220e-01
Loss: 1.219e-01
Loss: 1.219e-01
Loss: 1.218e-01
Loss: 1.218e-01
Loss: 1.217e-01
Loss: 1.216e-01
Loss: 1.216e-01
Loss: 1.215e-01
Loss: 1.215e-01
Loss: 1.214e-01
Loss: 1.214e-01
Loss: 1.213e-01
Loss: 1.212e-01
Loss: 1.212e-01
Loss: 1.211e-01
Loss: 1.210e-01
Loss: 1.210e-01
Loss: 1.209e-01
Loss: 1.208e-01
Loss: 1.208e-01
Loss: 1.207e-01
Loss: 1.206e-01
Loss: 1.206e-01
Loss: 1.205e-01
Loss: 1.205e-01
Loss: 1.204e-01
Loss: 1.203e-01
Loss: 1.205e-01
Loss: 1.203e-01
Loss: 1.202e-01
Loss: 1.201e-01
Loss: 1.201e-01
Loss: 1.200e-01
Loss: 1.200e-01
Loss: 1.199e-01
Loss: 1.199e-01
Loss: 1.198e-01
Loss: 1.197e-01
Loss: 1.197e-01
Loss: 1.196e-01
Loss: 1.195e-01
Loss: 1.195e-01
Loss: 1.194e-01
Loss: 1.194e-01
Loss: 1.193e-01
Loss: 1.192e-01
Loss: 1.192e-01
Loss: 1.191e-01
Loss: 1.190e-01
Loss: 1.190e-01
Loss: 1.189e-01
Loss: 1.189e-01
Loss: 1.188e-01
Loss: 1.188e-01
Loss: 1.187e-01
Loss: 1.186e-01
Loss: 1.186e-01
Loss: 1.185e-01
Loss: 1.185e-01
Loss: 1.184e-01
Loss: 1.183e-01
Loss: 1.183e-01
Loss: 1.182e-01
Loss: 1.182e-01
Loss: 1.181e-01
Loss: 1.181e-01
Loss: 1.181e-01
Loss: 1.180e-01
Loss: 1.180e-01
Loss: 1.179e-01
Loss: 1.179e-01
Loss: 1.178e-01
Loss: 1.178e-01
Loss: 1.177e-01
Loss: 1.177e-01
Loss: 1.176e-01
Loss: 1.176e-01
Loss: 1.175e-01
Loss: 1.175e-01
Loss: 1.174e-01
Loss: 1.174e-01
Loss: 1.173e-01
Loss: 1.173e-01
Loss: 1.172e-01
Loss: 1.172e-01
Loss: 1.171e-01
Loss: 1.170e-01
Loss: 1.170e-01
Loss: 1.169e-01
Loss: 1.169e-01
Loss: 1.168e-01
Loss: 1.168e-01
Loss: 1.167e-01
Loss: 1.167e-01
Loss: 1.166e-01
Loss: 1.166e-01
Loss: 1.165e-01
Loss: 1.164e-01
Loss: 1.164e-01
Loss: 1.164e-01
Loss: 1.163e-01
Loss: 1.163e-01
Loss: 1.162e-01
Loss: 1.161e-01
Loss: 1.161e-01
Loss: 1.160e-01
Loss: 1.160e-01
Loss: 1.159e-01
Loss: 1.158e-01
Loss: 1.158e-01
Loss: 1.157e-01
Loss: 1.157e-01
Loss: 1.156e-01
Loss: 1.156e-01
Loss: 1.155e-01
Loss: 1.155e-01
Loss: 1.155e-01
Loss: 1.154e-01
Loss: 1.154e-01
Loss: 1.153e-01
Loss: 1.153e-01
Loss: 1.152e-01
Loss: 1.152e-01
Loss: 1.151e-01
Loss: 1.151e-01
Loss: 1.151e-01
Loss: 1.151e-01
Loss: 1.150e-01
Loss: 1.150e-01
Loss: 1.149e-01
Loss: 1.149e-01
Loss: 1.149e-01
Loss: 1.148e-01
Loss: 1.148e-01
Loss: 1.147e-01
Loss: 1.147e-01
Loss: 1.146e-01
Loss: 1.147e-01
Loss: 1.146e-01
Loss: 1.145e-01
Loss: 1.145e-01
Loss: 1.145e-01
Loss: 1.145e-01
Loss: 1.144e-01
Loss: 1.144e-01
Loss: 1.143e-01
Loss: 1.144e-01
Loss: 1.143e-01
Loss: 1.143e-01
Loss: 1.142e-01
Loss: 1.142e-01
Loss: 1.142e-01
Loss: 1.141e-01
Loss: 1.141e-01
Loss: 1.140e-01
Loss: 1.140e-01
Loss: 1.139e-01
Loss: 1.139e-01
Loss: 1.139e-01
Loss: 1.138e-01
Loss: 1.138e-01
Loss: 1.137e-01
Loss: 1.137e-01
Loss: 1.136e-01
Loss: 1.136e-01
Loss: 1.135e-01
Loss: 1.135e-01
Loss: 1.134e-01
Loss: 1.134e-01
Loss: 1.133e-01
Loss: 1.132e-01
Loss: 1.132e-01
Loss: 1.131e-01
Loss: 1.131e-01
Loss: 1.130e-01
Loss: 1.129e-01
Loss: 1.129e-01
Loss: 1.129e-01
Loss: 1.128e-01
Loss: 1.128e-01
Loss: 1.127e-01
Loss: 1.127e-01
Loss: 1.127e-01
Loss: 1.126e-01
Loss: 1.126e-01
Loss: 1.125e-01
Loss: 1.124e-01
Loss: 1.124e-01
Loss: 1.123e-01
Loss: 1.123e-01
Loss: 1.122e-01
Loss: 1.122e-01
Loss: 1.121e-01
Loss: 1.121e-01
Loss: 1.120e-01
Loss: 1.120e-01
Loss: 1.120e-01
Loss: 1.119e-01
Loss: 1.120e-01
Loss: 1.119e-01
Loss: 1.118e-01
Loss: 1.118e-01
Loss: 1.117e-01
Loss: 1.116e-01
Loss: 1.116e-01
Loss: 1.115e-01
Loss: 1.115e-01
Loss: 1.114e-01
Loss: 1.115e-01
Loss: 1.114e-01
Loss: 1.113e-01
Loss: 1.113e-01
Loss: 1.112e-01
Loss: 1.112e-01
Loss: 1.111e-01
Loss: 1.111e-01
Loss: 1.110e-01
Loss: 1.110e-01
Loss: 1.109e-01
Loss: 1.109e-01
Loss: 1.108e-01
Loss: 1.107e-01
Loss: 1.107e-01
Loss: 1.106e-01
Loss: 1.105e-01
Loss: 1.105e-01
Loss: 1.104e-01
Loss: 1.104e-01
Loss: 1.103e-01
Loss: 1.103e-01
Loss: 1.102e-01
Loss: 1.102e-01
Loss: 1.101e-01
Loss: 1.101e-01
Loss: 1.100e-01
Loss: 1.100e-01
Loss: 1.099e-01
Loss: 1.099e-01
Loss: 1.098e-01
Loss: 1.097e-01
Loss: 1.097e-01
Loss: 1.097e-01
Loss: 1.096e-01
Loss: 1.096e-01
Loss: 1.095e-01
Loss: 1.094e-01
Loss: 1.095e-01
Loss: 1.094e-01
Loss: 1.093e-01
Loss: 1.093e-01
Loss: 1.093e-01
Loss: 1.092e-01
Loss: 1.092e-01
Loss: 1.092e-01
Loss: 1.091e-01
Loss: 1.091e-01
Loss: 1.091e-01
Loss: 1.090e-01
Loss: 1.090e-01
Loss: 1.089e-01
Loss: 1.089e-01
Loss: 1.088e-01
Loss: 1.087e-01
Loss: 1.087e-01
Loss: 1.086e-01
Loss: 1.086e-01
Loss: 1.085e-01
Loss: 1.085e-01
Loss: 1.084e-01
Loss: 1.083e-01
Loss: 1.082e-01
Loss: 1.082e-01
Loss: 1.082e-01
Loss: 1.081e-01
Loss: 1.080e-01
Loss: 1.079e-01
Loss: 1.079e-01
Loss: 1.079e-01
Loss: 1.078e-01
Loss: 1.077e-01
Loss: 1.076e-01
Loss: 1.076e-01
Loss: 1.076e-01
Loss: 1.075e-01
Loss: 1.074e-01
Loss: 1.074e-01
Loss: 1.073e-01
Loss: 1.073e-01
Loss: 1.073e-01
Loss: 1.072e-01
Loss: 1.072e-01
Loss: 1.071e-01
Loss: 1.070e-01
Loss: 1.070e-01
Loss: 1.069e-01
Loss: 1.069e-01
Loss: 1.068e-01
Loss: 1.068e-01
Loss: 1.067e-01
Loss: 1.066e-01
Loss: 1.065e-01
Loss: 1.065e-01
Loss: 1.065e-01
Loss: 1.064e-01
Loss: 1.064e-01
Loss: 1.063e-01
Loss: 1.063e-01
Loss: 1.062e-01
Loss: 1.062e-01
Loss: 1.061e-01
Loss: 1.061e-01
Loss: 1.061e-01
Loss: 1.060e-01
Loss: 1.060e-01
Loss: 1.059e-01
Loss: 1.058e-01
Loss: 1.058e-01
Loss: 1.057e-01
Loss: 1.057e-01
Loss: 1.056e-01
Loss: 1.056e-01
Loss: 1.055e-01
Loss: 1.054e-01
Loss: 1.054e-01
Loss: 1.053e-01
Loss: 1.052e-01
Loss: 1.052e-01
Loss: 1.052e-01
Loss: 1.051e-01
Loss: 1.051e-01
Loss: 1.050e-01
Loss: 1.049e-01
Loss: 1.049e-01
Loss: 1.048e-01
Loss: 1.047e-01
Loss: 1.046e-01
Loss: 1.046e-01
Loss: 1.045e-01
Loss: 1.044e-01
Loss: 1.044e-01
Loss: 1.043e-01
Loss: 1.043e-01
Loss: 1.042e-01
Loss: 1.042e-01
Loss: 1.041e-01
Loss: 1.041e-01
Loss: 1.040e-01
Loss: 1.039e-01
Loss: 1.039e-01
Loss: 1.038e-01
Loss: 1.037e-01
Loss: 1.037e-01
Loss: 1.036e-01
Loss: 1.036e-01
Loss: 1.035e-01
L-BFGS-B training ended after 1750 s
Start Adam training
Post Adam it 0 - Loss value :  1.035e-01
Adam training ended after 605 s
GPU use after training
| ID | GPU | MEM |
------------------
|  0 |  4% | 96% |
End of training
--------------------------------------------
Error details
--------------------------------------------

Border 7.0281652e-15
Loss eqs. modes 0.012262916
Loss eqs. int time 0.01146621
Loss mesures training 0.0797883
Loss mesures validation 0.10625769
Saving NN Model...
Model exported in OutputPythonScript_Surrogates/ModalPINN_Ur_0.08_Re_265.861_loc_cylinder_pitot_twoZones_True_sparse_True_552
Saving convergence history...
History exported in OutputPythonScript_Surrogates/ModalPINN_Ur_0.08_Re_265.861_loc_cylinder_pitot_twoZones_True_sparse_True_552
Saving modes shapes...
Modes shape exported in OutputPythonScript_Surrogates/ModalPINN_Ur_0.08_Re_265.861_loc_cylinder_pitot_twoZones_True_sparse_True_552
Saving comparison history...
Simulation data reading...
Reading flow...
202.575
202.650
202.725
202.800
202.875
202.950
203.025
203.100
203.175
203.250
203.325
203.400
203.475
203.550
203.625
203.700
203.775
203.850
203.925
204.000
204.075
204.150
204.225
204.300
204.375
204.450
204.525
204.600
204.675
204.750
204.825
204.900
204.975
205.050
205.125
205.200
205.275
205.350
205.425
205.500
205.575
205.650
205.725
205.800
205.875
205.950
206.025
206.100
206.175
206.250
206.325
206.400
206.475
206.550
206.625
206.700
206.775
206.850
206.925
207.000
207.075
207.150
207.225
207.300
207.375
207.450
207.525
207.600
207.675
207.750
207.825
207.900
207.975
208.050
208.125
208.200
208.275
208.350
208.425
208.500
208.575
208.650
208.725
208.800
208.875
208.950
209.025
209.100
209.175
209.250
209.325
209.400
209.475
209.550
209.625
209.700
209.775
209.850
209.925
210.000
210.075
210.150
210.225
210.300
210.375
210.450
210.525
210.600
210.675
210.750
210.825
210.900
210.975
211.050
211.125
211.200
211.275
211.350
211.425
211.500
211.575
211.650
211.725
211.800
211.875
211.950
212.025
212.100
212.175
212.250
212.325
212.400
212.475
212.550
212.625
212.700
212.775
212.850
212.925
213.000
213.075
213.150
213.225
213.300
213.375
213.450
213.525
213.600
213.675
213.750
213.825
213.900
213.975
214.050
214.125
214.200
214.275
214.350
214.425
214.500
214.575
214.650
214.725
214.800
214.875
214.950
215.025
215.100
215.175
215.250
215.325
215.400
215.475
215.550
215.625
215.700
215.775
215.850
215.925
216.000
216.075
216.150
216.225
216.300
216.375
216.450
216.525
216.600
216.675
216.750
216.825
216.900
216.975
217.050
217.125
217.200
217.275
217.350
217.425
217.500
217.575
217.650
217.725
217.800
217.875
217.950
218.025
218.100
218.175
218.250
218.325
218.400
218.475
218.550
218.625
218.700
218.775
218.850
218.925
219.000
219.075
219.150
219.225
219.300
219.375
219.450
219.525
219.600
219.675
219.750
219.825
219.900
219.975
220.050
220.125
220.200
220.275
220.350
220.425
220.500
220.575
220.650
220.725
220.800
220.875
220.950
221.025
221.100
221.175
221.250
221.325
221.400
221.475
221.550
221.625
221.700
221.775
221.850
221.925
222.000
222.075
222.150
222.225
222.300
222.375
222.450
222.525
222.600
222.675
222.750
222.825
222.900
222.975
223.050
223.125
223.200
223.275
223.350
223.425
223.500
223.575
223.650
223.725
223.800
223.875
223.950
224.025
224.100
224.175
224.250
224.325
224.400
224.475
224.550
224.625
224.700
224.775
224.850
224.925
225.000
Done!
CPU_TIME = 24.238048 seconds
Reading and cropping simulation data ... ok
Comparison history exported in OutputPythonScript_Surrogates/ModalPINN_Ur_0.08_Re_265.861_loc_cylinder_pitot_twoZones_True_sparse_True_552
Saving forces ...
Forces exported
End of program
